# -*- coding: utf-8 -*-
"""run_oct2hist.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/WinetraubLab/OCT2Hist-ModelInference/blob/main/run_oct2hist.ipynb

# Overview
Use this notebook to convert an OCT image to virtual histology.

To get started,
[open this notebook in colab](https://colab.research.google.com/github/WinetraubLab/OCT2Hist-ModelInference/blob/main/run_oct2hist.ipynb) and run.
"""
import sys

import numpy
import pandas
import pandas as pd
import torch
from matplotlib.patches import Patch
from segment_anything import sam_model_registry, SamPredictor
from tqdm import tqdm
from OCT2Hist_UseModel.utils.masking import get_sam_input_points, show_points, show_mask, mask_gel_and_low_signal

from OCT2Hist_UseModel.utils.crop import crop
from zero_shot_segmentation.zero_shot_utils.predict_mask_on_oct_interactive import predict

# from google.colab import drive
sys.path.append('./zero_shot_segmentation')
import cv2
import matplotlib.pyplot as plt

sys.path.append('./OCT2Hist_UseModel')
import os


# Define the Roboflow project URL and API key
rf_api_key= "R04BinsZcBZ6PsfKR2fP"
rf_workspace= "yolab-kmmfx"
rf_project_name = "11-16-2023-zero-shot-oct"
rf_dataset_type = "coco-segmentation" #"png-mask-semantic"
version = 5
CHECKPOINT_PATH = "weights/sam_vit_h_4b8939.pth"  # os.path.join("weights", "sam_vit_h_4b8939.pth")

roboflow_annot_dataset_dir = os.path.join(os.getcwd(),f"./11/16/2023-Zero-shot-OCT-{version}/test")
#TODO: change this:
raw_oct_dataset_dir = "/Users/dannybarash/Library/CloudStorage/GoogleDrive-dannybarash7@gmail.com/Shared drives/Yolab - Current Projects/Yonatan/Hist Images/"
real_histology_dir = raw_oct_dataset_dir

#roboflow semantic classes
EPIDERMIS = True #mask values for epidermis mask

import numpy as np
from PIL import Image, ImageDraw

def coco_mask_to_numpy(image_shape, coco_mask):
    """
    Convert COCO format segmentation mask to a NumPy array.

    Parameters:
    - image_shape: Tuple (m, n) representing the shape of the image.
    - coco_mask: List of coordinates [x1, y1, x2, y2, ..., xn, yn] in COCO format.

    Returns:
    - numpy_mask: NumPy array of shape (m, n) with True within the mask boundaries and False elsewhere.
    """
    # Create an image and draw the polygon defined by the COCO mask
    mask_image = Image.new("1", image_shape[::-1], 0)
    draw = ImageDraw.Draw(mask_image)
    draw.polygon(coco_mask, outline=1, fill=1)
    del draw

    # Convert the mask image to a NumPy array
    numpy_mask = np.array(mask_image, dtype=bool)

    return numpy_mask

# Function to download images and masks from Roboflow
def download_images_and_masks(api_key, workspace, project_name, dataset_name, version):
    from roboflow import Roboflow
    rf = Roboflow(api_key=api_key)
    project = rf.workspace(workspace).project(project_name)
    dataset = project.version(version).download(rf_dataset_type, overwrite = True)
    return dataset

# Function to calculate Intersection over Union (IoU)
def calculate_iou(mask_true, mask_pred, class_id):
    #intersection = np.logical_and(mask_true == class_id, mask_pred == class_id)
    intersection = np.logical_and(mask_true, mask_pred == class_id)
    union = np.logical_or(mask_true, mask_pred == class_id)

    class_iou = np.sum(intersection) / np.sum(union)
    return class_iou

    mask_pred_bool = mask_pred.astype(bool)
def make_mask_drawable(mask):
    mask = mask.astype(np.uint8)
    mask[mask == 1] = 255
    return mask

def extract_filename_prefix(filename):
    # Split the filename based on the dot ('.') and take the first part
    prefix = filename.split('.')[0]

    # Remove the "_jpg" part if it exists
    if prefix.endswith('_jpg'):
        prefix = prefix[:-4]

    return prefix

# Download images and masks
dataset = download_images_and_masks(rf_api_key, rf_workspace, rf_project_name, rf_dataset_type, version)
# prepare model
DEVICE = torch.device('mps')  # 'cpu'
MODEL_TYPE = "vit_h"
sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)
predictor = SamPredictor(sam)


total_iou_vhist = 0
total_samples_vhist = 0

# Get the list of image files
image_files = [f for f in os.listdir(roboflow_annot_dataset_dir) if f.endswith(".jpg")]
image_files = image_files[1:]
total_iou_vhist = {EPIDERMIS:0}  # DERMIS:0 , # IOU for each class
total_iou_oct = {EPIDERMIS:0}
total_samples_vhist = 0
total_samples_oct = 0
path_to_annotations = os.path.join(roboflow_annot_dataset_dir, "_annotations.coco.json")
from pylabel import importer
dataset = importer.ImportCoco(path_to_annotations, path_to_images=roboflow_annot_dataset_dir, name="zero_shot_oct")
visualize_input_gt = True
visualize_input_hist = True
visualize_pred_vs_gt_vhist = True
visualize_pred_vs_gt_oct = True
visualize_pred_over_vhist = True
visualize_input_vhist = True
segment_real_hist = False
output_image_dir = "./images"
if not os.path.exists(output_image_dir):
    os.makedirs(output_image_dir)

index_array = [extract_filename_prefix(file) for file in image_files]
df = pd.DataFrame({
    "iou_vhist": numpy.nan,  # Replace with your data for "iou vhist"
    "iou_oct": numpy.nan     # Replace with your data for "iou oct"
}, index=index_array)
i =0
for oct_fname in tqdm(image_files):

    # if not extract_filename_prefix(image_file).startswith("LE-03-Slide04_Section01_yp0_A"):
    #     continue
    is_real_histology = oct_fname.find("_B_") != -1
    if is_real_histology:
        continue
    i += 1
    image_name = extract_filename_prefix(oct_fname)
    print(f"image number {i}: {image_name}")
    image_path = os.path.join(roboflow_annot_dataset_dir, oct_fname)
    oct_img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    real_histology_image_name = image_name.replace("_A","_B")
    real_histology_fname=dataset.df.img_filename[dataset.df.img_filename.str.startswith(real_histology_image_name)].values[0]
    real_histology_path = os.path.join(roboflow_annot_dataset_dir, real_histology_fname)
    real_hist_img = cv2.imread(real_histology_path, cv2.IMREAD_UNCHANGED)

    coco_mask = dataset.df.ann_segmentation[dataset.df.img_filename == real_histology_fname].values[0][0]
    mask_true = coco_mask_to_numpy(oct_img.shape, coco_mask)
    if visualize_input_gt:
        plt.figure(figsize=(5, 5))
        plt.imshow(oct_img, cmap = "gray")
        show_mask(mask_true, plt.gca(), alpha=0.3)
        plt.axis('off')
        plt.suptitle(f"Input oct and ground truth mask")
        plt.title(f"{image_name}")
        plt.savefig(f'{os.path.join(output_image_dir,image_name)}_input_gt.png')
        plt.close('all')
    if visualize_input_hist:
        plt.figure(figsize=(5, 5))
        plt.imshow(real_hist_img)
        show_mask(mask_true, plt.gca(), alpha=0.3)
        plt.axis('off')
        plt.suptitle(f"Input real histology and ground truth mask")
        plt.title(f"{image_name}")
        plt.savefig(f'{os.path.join(output_image_dir, image_name)}_input_hist.png')
        plt.close('all')


    oct_mask, _, crop_args, n_points_used, warped_mask_true = predict(image_path, mask_true, weights_path=CHECKPOINT_PATH,
                                                        vhist=False)
    cropped_mask_gt = crop(warped_mask_true, **crop_args)
    cropped_oct_image = crop(oct_img, **crop_args)

    epidermis_iou_oct = calculate_iou(cropped_mask_gt, oct_mask, EPIDERMIS)
    total_iou_oct[EPIDERMIS] += epidermis_iou_oct
    df.loc[image_name, "iou_oct"] = epidermis_iou_oct
    if visualize_pred_vs_gt_oct:
        plt.figure(figsize=(5, 5))
        plt.imshow(cropped_oct_image, cmap="gray")
        c1 = show_mask(oct_mask, plt.gca())
        c2 = show_mask(cropped_mask_gt, plt.gca(), random_color=True, alpha = 0.2)
        plt.axis('off')
        plt.suptitle(f"oct segmentation w/o vhist: iou {epidermis_iou_oct:.2f}, {n_points_used} clicks")
        plt.title(f"{image_name}")
        legend_elements = [
            Patch(color=c1, alpha=1, label='Yours'),
            Patch(color=c2, alpha=1, label='GT'),
        ]
        plt.legend(handles=legend_elements)
        plt.savefig(f'{os.path.join(output_image_dir, image_name)}_pred_wo_vhist.png')
        plt.close()
    total_samples_oct+=1

    mask, virtual_histology_image, crop_args, n_points_used, warped_mask_true = predict(image_path, mask_true, weights_path = CHECKPOINT_PATH)


    if visualize_input_vhist:
        plt.figure(figsize=(5, 5))
        plt.imshow(virtual_histology_image)
        show_mask(cropped_mask_gt, plt.gca(), alpha = 0.6)
        plt.axis('off')
        plt.suptitle(f"Input vhist and ground truth mask")
        plt.title(f"name {image_name}")
        plt.savefig(f'{os.path.join(output_image_dir,image_name)}_input_vhist.png')
        plt.close()


    if segment_real_hist:
        image_path = os.path.join(real_histology_dir, oct_fname)
        oct_mask, _, crop_args = predict(image_path, predictor, weights_path=CHECKPOINT_PATH, vhist=False)

    if mask is None or mask.sum().sum()==0:
        print(f"Could not segment {image_path}.")
        continue
    mask[mask==1] = True
    mask[mask == 0] = False
    #mask_pred = cv2.resize(mask_pred, (mask_true.shape[1], mask_true.shape[0]), interpolation =  cv2.INTER_NEAREST)
    cropped_oct_image = crop(oct_img, **crop_args)
    # Calculate IoU for each class# DERMIS
    epidermis_iou_vhist = calculate_iou(cropped_mask_gt, mask, EPIDERMIS)
    df.loc[image_name,"iou_vhist"] = epidermis_iou_vhist
    total_iou_vhist[EPIDERMIS] += epidermis_iou_vhist
    total_samples_vhist += 1

    if visualize_pred_over_vhist:
        plt.figure(figsize=(5, 5))
        plt.imshow(virtual_histology_image)
        c1 = show_mask(mask, plt.gca())
        c2 = show_mask(cropped_mask_gt, plt.gca(), random_color=True, alpha = 0.6)
        plt.axis('off')
        plt.suptitle(f"vhist segmentation: iou {epidermis_iou_vhist:.2f}, {n_points_used} clicks")
        plt.title(f"{image_name}")
        # Add a legend
        legend_elements = [
            Patch(color=c1, alpha=1, label='Yours'),
            Patch(color=c2, alpha=1, label='GT'),
        ]
        plt.legend(handles=legend_elements)
        plt.savefig(f'{os.path.join(output_image_dir, image_name)}_vhist_pred.png')
        plt.close()

    if visualize_pred_vs_gt_vhist:
        plt.figure(figsize=(5, 5))
        plt.imshow(cropped_oct_image, cmap = "gray")
        c1 = show_mask(mask, plt.gca())
        c2 = show_mask(cropped_mask_gt, plt.gca(), random_color=True, alpha = 0.2)
        plt.axis('off')
        plt.suptitle(f"oct and vhist segmentation: iou {epidermis_iou_vhist:.2f}, {n_points_used} clicks")
        plt.title(f"{image_name}")
        # Add a legend
        legend_elements = [
            Patch(color=c1, alpha=1, label='Yours'),
            Patch(color=c2, alpha=1, label='GT'),
        ]
        plt.legend(handles=legend_elements)
        plt.savefig(f'{os.path.join(output_image_dir, image_name)}_oct_pred_with_vhist.png')
        plt.close()



    df.to_csv(os.path.join(output_image_dir, 'iou_scores.csv'), index=True)


average_iou = total_iou_vhist[EPIDERMIS] / total_samples_vhist #sum all ious divided by (number of images * number of classes).
print(f"Average IoU with virtual histology: {average_iou}")
average_iou_oct = total_iou_oct[EPIDERMIS] / total_samples_oct
print(f"Average IoU without virtual histology: {average_iou_oct}")
