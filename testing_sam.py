# -*- coding: utf-8 -*-
"""testing_sam.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/WinetraubLab/zero_shot_segmentation/blob/main/testing_sam.ipynb

# Overview
Use this notebook to convert an OCT image you have to a virtual H&E image for evaluation.

To get started,
[open this notebook in colab](https://colab.research.google.com/github/WinetraubLab/zero_shot_segmentation/blob/main/testing_sam.ipynb)
 and run.

# inputs

Assumptions:

oct scan x/z rates:
*   microns per pixel z = 1
*   microns per pixel x = 1

pix2pix input sizes:
*   virtual histology input width = 256
*   virtual histology input height = 256

pix2pix input x/z rates:
*   microns per pixel z = 1
*   microns per pixel x = 2
"""
import os

from segment_anything import SamAutomaticMaskGenerator, sam_model_registry

#segment anything (sam)
using_colab = False
visualize_sam_outputs = True

#sam algorithm input parameters
points_per_side=32
pred_iou_thresh=0.90
stability_score_thresh=0.95
crop_n_layers=1
crop_n_points_downscale_factor=2
min_mask_region_area=3000

#sam model type and weights checkpoint
sam_checkpoint = "sam_vit_h_4b8939.pth"
model_type = "vit_h"

FIG_SIZE = (5,5)

#rf - roboflow dataset related params
rf_api_key="R04BinsZcBZ6PsfKR2fP"
rf_workspace="yolab-kmmfx"
rf_project = "connect_from_colab"
rf_dataset = "png-mask-semantic"

"""#Zero shot pipeline"""

# Path to an OCT image to convert
vhist_input_image_path = "/Users/dannybarash/Library/CloudStorage/GoogleDrive-dannybarash7@gmail.com/Shared drives/Yolab - Current Projects/Danny - Zero Shot Learning on OCT/VirtualHist/croppedimage2.vhist.png"
oct_input_image_path = "/Users/dannybarash/Library/CloudStorage/GoogleDrive-dannybarash7@gmail.com/Shared drives/Yolab - Current Projects/Emilie/z-stacking/croppedimage2.png"

# Commented out IPython magic to ensure Python compatibility.
# %pip install dataclasses-json
# %pip install supervision
from IPython.display import clear_output
clear_output()

from zero_shot_segmentation.zero_shot_utils.utils import *

"""#run sam on virtual histology

## Environment Set-up
"""

# Commented out IPython magic to ensure Python compatibility.
# %run /content/zero_shot_segmentation/setup_roboflow_and_sam.ipynb
from IPython.display import clear_output
clear_output()

"""To generate masks, just run `generate` on an image."""

import cv2

input = cv2.imread(vhist_input_image_path)
HOME = "/Users/dannybarash/Code/oct/zero_shot_segmentation_test_sam"
CHECKPOINT_PATH = os.path.join(HOME, "weights", "sam_vit_h_4b8939.pth")
print(CHECKPOINT_PATH, "; exist:", os.path.isfile(CHECKPOINT_PATH))
DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
MODEL_TYPE = "vit_h"
sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)

mask_generator = SamAutomaticMaskGenerator(sam)

masks = mask_generator.generate(input)

from OCT2Hist_UseModel.utils.show_images import *
showImg(input)

if visualize_sam_outputs:
  visualize_masks(masks)

"""Mask generation returns a list over masks, where each mask is a dictionary containing various data about the mask. These keys are:
* `segmentation` : the mask
* `area` : the area of the mask in pixels
* `bbox` : the boundary box of the mask in XYWH format
* `predicted_iou` : the model's own prediction for the quality of the mask
* `point_coords` : the sampled input point that generated this mask
* `stability_score` : an additional measure of mask quality
* `crop_box` : the crop of the image used to generate this mask in XYWH format

Show all the masks overlayed on the image.

## Automatic mask generation options

There are several tunable parameters in automatic mask generation that control how densely points are sampled and what the thresholds are for removing low quality or duplicate masks. Additionally, generation can be automatically run on crops of the image to get improved performance on smaller objects, and post-processing can remove stray pixels and holes. Here is an example configuration that samples more masks:[link text](https://)
"""

if visualize_sam_outputs:
  visualize_masks(masks)

"""#project on oct"""

visualize_masks_on_img(input, masks, FIG_SIZE)

oct_input = cv2.imread(oct_input_image_path)
showImg(oct_input)

for points_per_side in [10,15,20]:
  mask_generator_2 = SamAutomaticMaskGenerator(
      model=sam,
      points_per_side=32,
      pred_iou_thresh=0.86,
      stability_score_thresh=0.92,
      crop_n_layers=1,
      crop_n_points_downscale_factor=2,
      min_mask_region_area=500,  # Requires open-cv to run post-processing
  )
  masks2 = mask_generator_2.generate(input)
  visualize_masks_on_img(oct_input, masks2, FIG_SIZE)

mask_generator_2 = SamAutomaticMaskGenerator(
    model=sam,
    points_per_side=10,
    pred_iou_thresh=0.95,
    stability_score_thresh=0.92,
    crop_n_layers=1,
    crop_n_points_downscale_factor=2,
    min_mask_region_area=500,  # Requires open-cv to run post-processing
)
masks2 = mask_generator_2.generate(input)
visualize_masks_on_img(oct_input, masks2, FIG_SIZE)

mask_generator_2 = SamAutomaticMaskGenerator(
    model=sam,
    points_per_side=10,
    pred_iou_thresh=0.95,
    stability_score_thresh=0.95,
    crop_n_layers=1,
    crop_n_points_downscale_factor=2,
    min_mask_region_area=500,  # Requires open-cv to run post-processing
)
masks2 = mask_generator_2.generate(input)
visualize_masks_on_img(oct_input, masks2, FIG_SIZE)

mask_generator_2 = SamAutomaticMaskGenerator(
    model=sam,
    points_per_side=10,
    pred_iou_thresh=0.95,
    stability_score_thresh=0.95,
    crop_n_layers=1,
    crop_n_points_downscale_factor=4,
    min_mask_region_area=500,  # Requires open-cv to run post-processing
)
masks2 = mask_generator_2.generate(input)
visualize_masks_on_img(oct_input, masks2, FIG_SIZE)

mask_generator_2 = SamAutomaticMaskGenerator(
    model=sam,
    points_per_side=100,
    pred_iou_thresh=0.95,
    stability_score_thresh=0.95,
    crop_n_layers=4,
    crop_n_points_downscale_factor=2,
    min_mask_region_area=500,  # Requires open-cv to run post-processing
)
masks2 = mask_generator_2.generate(input)
visualize_masks_on_img(oct_input, masks2, FIG_SIZE)

mask_generator_2 = SamAutomaticMaskGenerator(
    model=sam,
    points_per_side=100,
    pred_iou_thresh=0.95,
    stability_score_thresh=0.95,
    crop_n_layers=1,
    crop_n_points_downscale_factor=4,
    min_mask_region_area=500,  # Requires open-cv to run post-processing
)
masks2 = mask_generator_2.generate(input)
visualize_masks_on_img(oct_input, masks2, FIG_SIZE)
