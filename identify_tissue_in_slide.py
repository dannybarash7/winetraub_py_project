# -*- coding: utf-8 -*-
"""Identify Tissue In Slide.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14-xL2FscecdgSsBTJSTnmzfzXWPCWslr

This script identifies the tissue in virtual or real histology
"""
import os

image_directory = '/Users/dannybarash/Downloads/TestSet/'
#image_path = image_directory + 'LE-03-Slide04_Section01_yp0_patch01_fake_B.png'
#image_path = image_directory + 'LF-01-Slide02_Section01_yp0_patch01_fake_B.png'
#image_path = image_directory + 'LG-03-Slide06_Section01_yp0_patch01_fake_B.png'
image_path = image_directory + 'LG-07-Slide04_Section02_yp0_patch01_fake_B.png'
#image_path = image_directory + 'LG-39-Slide05_Section03_yp0_patch01_fake_B.png'
#image_path = image_directory + 'LG-62-Slide03_Section03_yp0_patch01_fake_B.png'

# Commented out IPython magic to ensure Python compatibility.
#@title Install
if not ('run_it' in locals() or 'run_it' in globals()):
  run_it = False
  # from google.colab import drive
  from IPython.display import clear_output

  # drive.mount('/content/drive/')
  # !git clone --recurse-submodules https://github.com/WinetraubLab/zero_shot_segmentation.git
  # !git clone --recurse-submodules https://github.com/WinetraubLab/OCT2Hist-ModelInference

  # !pip install torch
  # !pip install torchvision
#   %pip install dataclasses-json
#   %pip install supervision
  import torch
  import torchvision
  import sys
  import numpy as np

  sys.path.append('./zero_shot_segmentation')
  from zero_shot_utils.utils import visualize_masks_on_img
  import cv2
  import matplotlib.pyplot as plt

  sys.path.append('./OCT2Hist_UseModel')
  from utils.show_images import showImg

  # rf - roboflow
  rf_api_key="R04BinsZcBZ6PsfKR2fP"
  rf_workspace="yolab-kmmfx"
  rf_project = "connect_from_colab"
  rf_dataset = "png-mask-semantic"
  using_colab = True
  visualize_sam_outputs = True
  sam_checkpoint = "sam_vit_h_4b8939.pth"
  model_type = "vit_h"
#   %run /content/zero_shot_segmentation/setup_roboflow_and_sam.ipynb
image_path = "/Users/dannybarash/Downloads/TestSet/LG-07-Slide04_Section02_yp0_patch01_fake_B.png"
clear_output()

# @title Load Image
input = cv2.imread(image_path)
input = cv2.cvtColor(input, cv2.COLOR_BGR2RGB)
input_gray = cv2.cvtColor(input, cv2.COLOR_RGB2GRAY)

#input = cv2.resize(input, (50, 50), interpolation=cv2.INTER_AREA)
#showImg(input)

"""# Method 1: Automatic Mask Generator"""
DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
MODEL_TYPE = "vit_h"

from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor
CHECKPOINT_PATH = os.path.join("weights", "sam_vit_h_4b8939.pth")
sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)
# Parameters list: https://github.com/facebookresearch/segment-anything/blob/main/segment_anything/automatic_mask_generator.py#L35
mask_generator = SamAutomaticMaskGenerator(
    sam,
    points_per_side  = 3, # 32 relevant
    points_per_batch = 64,
    pred_iou_thresh  = 0.88, # relevant
    stability_score_thresh = 0.95,#0.7, # relevant (default is 0.95)
    stability_score_offset = 1.0, # relevant
    box_nms_thresh   = 0.7, # relevant
    crop_n_layers    = 0, # relevant
    crop_nms_thresh  = 0.7, # relevant
    crop_overlap_ratio = 512 / 1500, # relevant
    crop_n_points_downscale_factor = 1, # relevant
    point_grids = None,
    min_mask_region_area = 0, # relevant, default is 0
    #output_mode: str = "binary_mask",
)

# Run SAM
sam_masks = mask_generator.generate(input)

# Visualize SAM output
white_image = np.ones_like(input) * 255
#visualize_masks_on_img(white_image, sam_masks, (5,5))

# Loop over Masks, identify which one is the most likely to be the tissue
mask_to_use = None
for i in range(len(sam_masks)):
  mask = np.array(sam_masks[i]['segmentation'])
  rows, cols = mask.shape
  top_row = mask[0, :]
  bottom_row = mask[rows-1, :]

  if np.sum(top_row) < cols/4 and np.sum(bottom_row) < cols/4:
    # This mask is in the middle
    mask_to_use=i

# Visualize results
if mask_to_use == None or len(sam_masks)>3:
  print("Can't determine mask in this method")
  print(mask_to_use)
  print(len(sam_masks))
else:
  mask = np.array(sam_masks[mask_to_use]['segmentation'])

  plt.figure(figsize=(5,5))
  plt.imshow(input)

  color = np.array([30/255, 144/255, 255/255, 0.6])
  h, w = mask.shape[-2:]
  mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)
  plt.gca().imshow(mask_image)
  plt.show()

"""# Method 2: Point In Middle"""

from segment_anything import sam_model_registry, SamPredictor, SamAutomaticMaskGenerator
import matplotlib.pyplot as plt
predictor = SamPredictor(sam)
predictor.set_image(input)

# Calculate the moments of the binary image
mask = np.array(input_gray > 0)
moments = cv2.moments(mask.astype(np.uint8))

# Calculate the center of mass
cx = int(moments['m10'] / moments['m00'])
cy = int(moments['m01'] / moments['m00'])

# Mid point to the bottom
lowest_y = np.where(mask[:, cx])[0]
lowest_y = lowest_y[len(lowest_y)-1]
midpoint_y = (lowest_y*1 + cy*0.0).astype(int)-10
#nonzero_coords = np.column_stack(np.where(mask))
#closest_point = min(nonzero_coords, key=lambda point: np.linalg.norm(np.array(point) - np.array([cx, cy])))
#midpoint_y = (closest_point[0] + cy) *0.7

def show_points(coords, labels, ax, marker_size=375):
    pos_points = coords[labels==1]
    neg_points = coords[labels==0]
    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)
    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)


input_point = np.array([[cx, cy],[cx, midpoint_y],[127, 1]])
input_label = np.array([1,1,0])

masks, scores, logits = predictor.predict(
    point_coords=input_point,
    point_labels=input_label,
    multimask_output=False,
)

def show_mask(mask, ax, random_color=False):
    if random_color:
        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)
    else:
        color = np.array([30/255, 144/255, 255/255, 0.6])
    h, w = mask.shape[-2:]
    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)
    ax.imshow(mask_image)

for i, (mask, score) in enumerate(zip(masks, scores)):
    plt.figure(figsize=(5,5))
    plt.imshow(input)
    show_mask(mask, plt.gca())
    show_points(input_point, input_label, plt.gca())
    plt.title(f"Mask {i+1}, Score: {score:.3f}", fontsize=18)
    plt.axis('off')
    plt.show()
    plt.savefig('/content/figure.png')
    plt.close()

